"""
app.py â€“ Chat sobre PDF usando Together AI (LLMs open-source)
Requisitos (requirements.txt):
streamlit
langchain-community
sentence-transformers
faiss-cpu
pypdf
tiktoken
together-ai
"""

import os, time
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import together
from together.error import RateLimitError

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ConfiguraÃ§Ã£o da Together AI
#    Salve no Streamlit Cloud â†’ Settings â†’ Secrets:
#    TOGETHER_API_KEY = "sua_chave"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
together.api_key = st.secrets["TOGETHER_API_KEY"]
MODEL_NAME   = "mistralai/Mistral-7B-Instruct-v0.2"   # escolha outro na doc se quiser
MAX_OUT      = 256    # tokens de saÃ­da
K_CHUNKS     = 2      # nÂº de trechos que enviamos ao LLM

def ask_together(prompt: str) -> str:
    """Envia prompt ao Together AI e devolve texto."""
    resp = together.Complete.create(
        model=MODEL_NAME,
        prompt=prompt,
        max_tokens=MAX_OUT,
        temperature=0.1,
        stop=["</s>"],
    )
    return resp["choices"][0]["text"].strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) Interface Streamlit
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="PDF Chat (Together AI)", page_icon="ğŸ“„ğŸ¤–")
st.title("ğŸ“„ğŸ’¬ Assistente PDF â€“ Together AI")

pdf_file = st.file_uploader("ğŸ’¾ Envie um PDF", type="pdf")

if pdf_file:
    # â”€â”€ Salvar arquivo em /tmp
    tmp_path = f"/tmp/{pdf_file.name}"
    with open(tmp_path, "wb") as f:
        f.write(pdf_file.getbuffer())

    # â”€â”€ Carregar e dividir texto
    docs  = PyPDFLoader(tmp_path).load()
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100
    )
    chunks = splitter.split_documents(docs)

    # â”€â”€ Embeddings + Ã­ndice FAISS
    emb = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"},
    )
    vectordb  = FAISS.from_documents(chunks, emb)
    retriever = vectordb.as_retriever(search_kwargs={"k": K_CHUNKS})

    st.success("âœ… PDF processado! Pergunte algo abaixo.")
    query = st.text_input("Pergunta")

    if query:
        with st.spinner("Gerando respostaâ€¦"):
            # Montar contexto
            ctx_docs = retriever.get_relevant_documents(query)
            context  = "\n\n".join(d.page_content for d in ctx_docs)

            prompt = (
                "VocÃª Ã© um assistente que responde apenas a partir do contexto fornecido.\n"
                "Responda em portuguÃªs, de forma clara e objetiva.\n\n"
                f"Contexto:\n{context}\n\nPergunta: {query}\nResposta:"
            )

            try:
                answer = ask_together(prompt)
                st.markdown("### ğŸ¤– Resposta")
                st.write(answer)

                # Mostrar fontes
                st.markdown("### ğŸ“š Fontes")
                for i, d in enumerate(ctx_docs, 1):
                    src = d.metadata.get("source", pdf_file.name)
                    page = d.metadata.get("page", None)
                    lbl = f"{i}. {src}"
                    if page is not None:
                        lbl += f" â€“ pÃ¡gina {page+1}"
                    st.write(lbl)

            except RateLimitError:
                st.error(
                    "âš ï¸ VocÃª atingiu o limite gratuito da Together AI.\n"
                    "Aguarde alguns minutos ou ajuste o prompt/tokens."
                )
else:
    st.info("ğŸ“‚ FaÃ§a upload do PDF para comeÃ§ar.")
